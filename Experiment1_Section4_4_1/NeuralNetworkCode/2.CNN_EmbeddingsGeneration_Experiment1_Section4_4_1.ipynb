{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Generate the embeddings for Experiment 1, 4.4.1 Multiclass Classification of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    " \n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "#from models import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLA(\n",
      "  (base): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer3): Tree(\n",
      "    (root): Root(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (left_node): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (right_node): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Tree(\n",
      "    (root): Root(\n",
      "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (level_1): Tree(\n",
      "      (root): Root(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (left_node): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (right_node): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (prev_root): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (left_node): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (right_node): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer5): Tree(\n",
      "    (root): Root(\n",
      "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (level_1): Tree(\n",
      "      (root): Root(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (left_node): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (right_node): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (prev_root): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (left_node): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (right_node): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer6): Tree(\n",
      "    (root): Root(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (left_node): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (right_node): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear1): Linear(in_features=512, out_features=16, bias=True)\n",
      "  (linear2): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n",
      "(tensor([[0.0909, 0.0754, 0.0819, 0.1367, 0.1080, 0.1404, 0.0799, 0.0773, 0.1175,\n",
      "         0.0920]], grad_fn=<SoftmaxBackward>), tensor([[ 0.5252,  0.0234, -0.0692, -0.1895,  0.2503,  0.0717,  0.0286,  0.1297,\n",
      "          0.1956, -0.4529,  0.0711,  0.2681,  0.2794,  0.1389,  0.4511,  0.2981]],\n",
      "       grad_fn=<AddmmBackward>))\n"
     ]
    }
   ],
   "source": [
    "'''DLA in PyTorch.\n",
    "Reference:\n",
    "    Deep Layer Aggregation. https://arxiv.org/abs/1707.06484\n",
    "'''\n",
    "'''\n",
    "Code taken from (with a permission published on the website https://github.com/kuangliu/pytorch-cifar/blob/master/LICENSE)\n",
    "https://github.com/kuangliu/pytorch-cifar/blob/master/models/dla.py\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Root(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1):\n",
    "        super(Root, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            stride=1, padding=(kernel_size - 1) // 2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        x = torch.cat(xs, 1)\n",
    "        out = F.relu(self.bn(self.conv(x)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Tree(nn.Module):\n",
    "    def __init__(self, block, in_channels, out_channels, level=1, stride=1):\n",
    "        super(Tree, self).__init__()\n",
    "        self.level = level\n",
    "        if level == 1:\n",
    "            self.root = Root(2*out_channels, out_channels)\n",
    "            self.left_node = block(in_channels, out_channels, stride=stride)\n",
    "            self.right_node = block(out_channels, out_channels, stride=1)\n",
    "        else:\n",
    "            self.root = Root((level+2)*out_channels, out_channels)\n",
    "            for i in reversed(range(1, level)):\n",
    "                subtree = Tree(block, in_channels, out_channels,\n",
    "                               level=i, stride=stride)\n",
    "                self.__setattr__('level_%d' % i, subtree)\n",
    "            self.prev_root = block(in_channels, out_channels, stride=stride)\n",
    "            self.left_node = block(out_channels, out_channels, stride=1)\n",
    "            self.right_node = block(out_channels, out_channels, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xs = [self.prev_root(x)] if self.level > 1 else []\n",
    "        for i in reversed(range(1, self.level)):\n",
    "            level_i = self.__getattr__('level_%d' % i)\n",
    "            x = level_i(x)\n",
    "            xs.append(x)\n",
    "        x = self.left_node(x)\n",
    "        xs.append(x)\n",
    "        x = self.right_node(x)\n",
    "        xs.append(x)\n",
    "        out = self.root(xs)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DLA(nn.Module):\n",
    "    def __init__(self, block=BasicBlock, num_classes=10):\n",
    "        super(DLA, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer3 = Tree(block,  32,  64, level=1, stride=1)\n",
    "        self.layer4 = Tree(block,  64, 128, level=2, stride=2)\n",
    "        self.layer5 = Tree(block, 128, 256, level=2, stride=2)\n",
    "        self.layer6 = Tree(block, 256, 512, level=1, stride=2)\n",
    "        self.linear1 = nn.Linear(512, embed_dim)\n",
    "        self.linear2 = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.base(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = self.linear1(out)\n",
    "        emb = out\n",
    "        out = self.linear2(out)\n",
    "        return F.softmax(out, dim=1), emb\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = DLA()\n",
    "    print(net)\n",
    "    x = torch.randn(1, 3, 32, 32)\n",
    "    y = net(x)\n",
    "    print(y)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After training etc. possible to just load the model\n",
    "# PLEASE NOTE: Here, due to the size of the model, we do not attach it, however, we show the loading as an example how to do it\n",
    "\n",
    "#net_pred = DLA()\n",
    "#net_pred.load_state_dict(torch.load('FinalModel_0.904DLA_CIFAR10.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16294634"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of parameters\n",
    "\n",
    "[param.nelement() for param in net_pred.parameters()]\n",
    "\n",
    "sum([param.nelement() for param in net_pred.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation necessary to apply to the images\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainset\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='/workspace/SPC_Embeddings/cifar-10-batches-py', train=True, download=False, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testset\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='/workspace/SPC_Embeddings/cifar-10-batches-py', train=False, download=False, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain predictions and embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase I: Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_idx = range(0, 50500, 500) # Up to 50500 as the last number is not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform check\n",
    "numbers_idx[100] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The length of the array\n",
    "len(numbers_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for turning the numbers into strings for adding into the file names\n",
    "def to_str(var):\n",
    "    return str(list(np.reshape(np.asarray(var), (1, np.size(var)))[0]))[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save the embeddings for Phase I: Training Data\n",
    "\n",
    "for i in range(1,101):\n",
    "    \n",
    "    # Create subset of train data with size 500\n",
    "    trainset_subset = torch.utils.data.Subset(trainset, range(numbers_idx[i-1], numbers_idx[i]))   \n",
    "    trainloader_indices = torch.utils.data.DataLoader(trainset_subset, batch_size=1)\n",
    "    \n",
    "    # Create containers to collect embeddings, predictions and true labels\n",
    "    predictions_label = []\n",
    "    predictions_output = []\n",
    "    embed_list = []\n",
    "    train_labels = []\n",
    "    \n",
    "    # Run classification and append the results\n",
    "    for s, data in enumerate(trainloader_indices): \n",
    "        net_pred.eval()\n",
    "        x, y_true = data\n",
    "        prediction, embed = net_pred(x)\n",
    "        prediction2 = prediction.detach().numpy()\n",
    "        current_class = y_true   \n",
    "        klasse = np.argmax(prediction2, axis=-1)\n",
    "        \n",
    "        embed_list.append(embed.detach().numpy())  \n",
    "        predictions_output.append(prediction2)  \n",
    "        predictions_label.append(klasse.astype(int)) \n",
    "        train_labels.append(y_true.detach().numpy())  \n",
    "    \n",
    "    # Create a table with predictions and true labels\n",
    "    predictions_traindata = pd.DataFrame(np.squeeze(predictions_output))\n",
    "    predictions_traindata['binary'] = predictions_label\n",
    "    predictions_traindata['true'] = train_labels\n",
    "    \n",
    "    # Save the files as .txt\n",
    "    \n",
    "    f = open(to_str(numbers_idx[i-1]) + 'to' + to_str(numbers_idx[i]) + 'train_labels_probabilities_classificationCIFAR10.txt', 'w')\n",
    "    np.savetxt(f, predictions_traindata)\n",
    "    f.close()\n",
    "    \n",
    "    f = open(to_str(numbers_idx[i-1]) + 'to' + to_str(numbers_idx[i]) + 'train_embeddings16d_classificationCIFAR10.txt', 'w')\n",
    "    np.savetxt(f, np.squeeze(embed_list))\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase II, in-control: Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_idx_test = range(0, 10500, 500) # Up to 10500 as the last number is not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform check\n",
    "numbers_idx_test[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of the array\n",
    "len(numbers_idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save the embeddings for Phase II, in-control: Test Data\n",
    "\n",
    "\n",
    "for i in range(1,21):\n",
    "    \n",
    "    # Create subset of test data with size 500\n",
    "    testset_subset = torch.utils.data.Subset(testset, range(numbers_idx_test[i-1], numbers_idx_test[i]))   \n",
    "    testloader_indices = torch.utils.data.DataLoader(testset_subset, batch_size=1)\n",
    "    \n",
    "    # Create containers to collect embeddings, predictions and true labels\n",
    "    predictions_label = []\n",
    "    predictions_output = []\n",
    "    embed_list = []\n",
    "    train_labels = []\n",
    "    \n",
    "    # Run classification and append the results\n",
    "    for s, data in enumerate(testloader_indices): \n",
    "        net_pred.eval()\n",
    "        x, y_true = data\n",
    "        prediction, embed = net_pred(x)\n",
    "        prediction2 = prediction.detach().numpy()\n",
    "        current_class = y_true   \n",
    "        klasse = np.argmax(prediction2, axis=-1)\n",
    "        \n",
    "        embed_list.append(embed.detach().numpy())  \n",
    "        predictions_output.append(prediction2)  \n",
    "        predictions_label.append(klasse.astype(int)) \n",
    "        train_labels.append(y_true.detach().numpy())  \n",
    "    \n",
    "    # Create a table with predictions and true labels\n",
    "    predictions_testdata = pd.DataFrame(np.squeeze(predictions_output))\n",
    "    predictions_testdata['binary'] = predictions_label\n",
    "    predictions_testdata['true'] = train_labels\n",
    "    \n",
    "    # Save the files as .txt\n",
    "    \n",
    "    f = open(to_str(numbers_idx[i-1]) + 'to' + to_str(numbers_idx[i]) + 'test_labels_probabilities_classificationCIFAR10.txt', 'w')\n",
    "    np.savetxt(f, predictions_testdata)\n",
    "    f.close()\n",
    "    \n",
    "    f = open(to_str(numbers_idx[i-1]) + 'to' + to_str(numbers_idx[i]) + 'test_embeddings16d_classificationCIFAR10.txt', 'w')\n",
    "    np.savetxt(f, np.squeeze(embed_list))\n",
    "    f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase II, out-of-control: Out-of-control data from CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset\n",
    "phase2_data = CIFAR100(download=True, root='./cifar-100-batches-py', transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering of the image indices\n",
    "\n",
    "train_indices, kangaroo_indices, butterfly_indices, rocket_indices, other_indices = [], [], [], [], []\n",
    "train_idx, kangaroo_idx, butterfly_idx, rocket_idx = phase2_data.class_to_idx['train'], phase2_data.class_to_idx['kangaroo'], phase2_data.class_to_idx['butterfly'], phase2_data.class_to_idx['rocket']\n",
    "for i in range(len(phase2_data)):\n",
    "    current_class = phase2_data[i][1]\n",
    "    if current_class == train_idx:\n",
    "        train_indices.append(i)\n",
    "    elif current_class == kangaroo_idx:\n",
    "        kangaroo_indices.append(i)\n",
    "    elif current_class == butterfly_idx:\n",
    "        butterfly_indices.append(i)\n",
    "    elif current_class == rocket_idx:\n",
    "        rocket_indices.append(i)\n",
    "    else:\n",
    "        other_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only 100 images for each of the classes for Phase II dataset\n",
    "\n",
    "train_indices = train_indices[:int(0.2 * len(train_indices))]\n",
    "kangaroo_indices = kangaroo_indices[:int(0.2 * len(kangaroo_indices))]\n",
    "butterfly_indices = butterfly_indices[:int(0.2 * len(butterfly_indices))]\n",
    "rocket_indices = rocket_indices[:int(0.2 * len(rocket_indices))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Illustration of one of the pictures\n",
    "\n",
    "img_phase2, label_phase2 = phase2_data[10737] # image of a rocket\n",
    "plt.imshow(img_phase2.permute(1, 2, 0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the names of the classes\n",
    "phaseII_indices = [train_indices, kangaroo_indices, butterfly_indices, rocket_indices]\n",
    "\n",
    "phaseII_classes = [\"train\", \"kangaroo\", \"butterfly\", \"rocket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save the embeddings for Phase II, out-of-control: Out-of-control data from CIFAR-100\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    # Create subset of train data with size 100\n",
    "    trainset_subset = torch.utils.data.Subset(phase2_data, phaseII_indices[i])   \n",
    "    trainloader_indices = torch.utils.data.DataLoader(trainset_subset, batch_size=1)\n",
    "    \n",
    "    # Create containers to collect embeddings, predictions and true labels\n",
    "    predictions_label = []\n",
    "    predictions_output = []\n",
    "    embed_list = []\n",
    "    train_labels = []\n",
    "    \n",
    "    # Run classification and append the results\n",
    "    for s, data in enumerate(trainloader_indices): \n",
    "        net_pred.eval()\n",
    "        x, y_true = data\n",
    "        prediction, embed = net_pred(x)\n",
    "        prediction2 = prediction.detach().numpy()\n",
    "        current_class = y_true   \n",
    "        klasse = np.argmax(prediction2, axis=-1)\n",
    "        \n",
    "        embed_list.append(embed.detach().numpy())  \n",
    "        predictions_output.append(prediction2)  \n",
    "        predictions_label.append(klasse.astype(int)) \n",
    "        train_labels.append(y_true.detach().numpy())  \n",
    "\n",
    "    # Save the files as .txt\n",
    "    \n",
    "    f = open(phaseII_classes[i] + 'PHASEII_embeddings16d_classificationCIFAR10.txt', 'w')\n",
    "    np.savetxt(f, np.squeeze(embed_list))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(phaseII_classes[i] + 'PHASEII_predictions_classificationCIFAR10.txt', 'w')\n",
    "    np.savetxt(f, np.squeeze(predictions_output))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(phaseII_classes[i] + 'PHASEII_binarypredictions_classificationCIFAR10.txt', 'w')\n",
    "    np.savetxt(f, np.squeeze(predictions_label))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remark: After generating and saving the embeddings, the rest of the analysis and monitoring happens in R "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
